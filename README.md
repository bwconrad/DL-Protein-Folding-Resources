# Amsfold Resources

## Alphafold 1
- [Paper](https://www.nature.com/articles/s41586-019-1923-7)
- [DeepMind Blog Post](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)
- [Andrew Senior's Talk](https://www.youtube.com/watch?v=uQ1uVbrIv-Q)

## Alphafold 2
- [DeepMind Blog Post](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)
- [CASP14 Presentation](https://xukui.cn/alphafold2.html)
- [Yannic Kilcher's Video Overview](https://www.youtube.com/watch?v=B9PL__gVxLI)
- [Fabian Fuchs' Blog Post](https://fabianfuchsml.github.io/alphafold2/)
- [Mohammed AlQuraishi's Blog Post](https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/)


## Equivariance
- [SE(3)-Transformers](https://arxiv.org/abs/2006.10503)
- [Iterative SE(3)-Transformers](https://arxiv.org/abs/2102.13419)
    - [Blog post](https://fabianfuchsml.github.io/se3iterative/)
- [Lie Transformer](https://arxiv.org/abs/2012.10885)
- [Steerable CNNs](https://arxiv.org/abs/1612.08498)
- [Tensor field networks](https://arxiv.org/abs/1802.08219)
- [Symmetry and Equivariance in Neural Networks Lecture](https://www.youtube.com/watch?v=8s0Ka6Y_kIM)
- [E(n) Equivariant Graph Neural Networks](https://arxiv.org/abs/2102.09844)

## Efficient Attention

## Biology Transformers 
- [MSA Transformer](https://www.biorxiv.org/content/10.1101/2021.02.12.430858v1)
    - Protein language model using tied axial attention.
    - MSA position embedding. 
- [BERTology Meets Biology: Interpreting Attention in Protein Language Models](https://arxiv.org/abs/2006.15222) 
    - [Video Review](https://www.youtube.com/watch?v=q6Kyvy1zLwQ)
    - Bert model trained on protein sequences. Evidence that the attention weights encode
      information about amino acids contacts.
